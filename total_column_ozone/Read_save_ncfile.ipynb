{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr # for netCDF4 \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open nc file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you open the file without a group defined, you get the global attributes with no variables. You need to include a group='PRODUCT' to get the data product.\n",
    "\n",
    "Beaware that if you do not know the group, you cannot use xarray. Instead use netCDF4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data Fields': <class 'netCDF4._netCDF4.Group'>\n",
      "group /Data Fields:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): float32 AveragingKernel(nlayer2, nlayer2, spatial, image), float32 CloudPressure(spatial, image), float32 ColumnAmountO3(spatial, image), float32 DegreesOfFreedomForSignal(spatial, image), float32 EstimatedError(spatial, image), int16 FinalAlgorithmFlags(spatial, image), float32 LayerEfficiency(nlayer2, spatial, image), float32 Nvalue(spatial, image, nwl), float32 O3BelowCloud(spatial, image), float32 Reflectivity340(spatial, image), float32 Reflectivity380(spatial, image), float32 Residue(spatial, image, nsignal), float32 StepOneO3(spatial, image), float32 StepTwoO3(spatial, image), float32 TerrainPressure(spatial, image), float32 dNdR(spatial, image, dim_reflectivity), float32 dR_dl(spatial, image), float32 EffectiveCloudFraction(spatial, image)\n",
      "    groups: , 'Geolocation Fields': <class 'netCDF4._netCDF4.Group'>\n",
      "group /Geolocation Fields:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): float32 Latitude(spatial, image), float32 Longitude(spatial, image), float32 RelativeAzimuthAngle(spatial, image), float32 SolarZenithAngle(spatial, image), float32 ViewingZenithAngle(spatial, image), float64 Time(image), int16 GroundPixelQualityFlags(spatial, image)\n",
      "    groups: , 'METADATA': <class 'netCDF4._netCDF4.Group'>\n",
      "group /METADATA:\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: ALGORITHM_SETTINGS}\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "file_path = r\"C:\\\\Users\\\\joonw\\\\Downloads\\\\GK2_GEMS_L2_20240308_2345_O3T_HE_DPRO_ORI.nc\"\n",
    "rootgrp = Dataset(file_path, \"r\")\n",
    "print(rootgrp.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tscanline = 357 ;\n",
      "\tground_pixel = 450 ;\n",
      "\ttime = 1 ;\n",
      "\tcorner = 4 ;\n",
      "\tlayer = 13 ;\n",
      "\tlevel = 14 ;\n",
      "\n",
      "variables:\n",
      "\tfloat64 scanline(scanline) ;\n",
      "\t\tscanline:units = 1 ;\n",
      "\t\tscanline:axis = Y ;\n",
      "\t\tscanline:long_name = along-track dimension index ;\n",
      "\t\tscanline:comment = This coordinate variable defines the indices along track; index starts at 0 ;\n",
      "\tfloat64 ground_pixel(ground_pixel) ;\n",
      "\t\tground_pixel:units = 1 ;\n",
      "\t\tground_pixel:axis = X ;\n",
      "\t\tground_pixel:long_name = across-track dimension index ;\n",
      "\t\tground_pixel:comment = This coordinate variable defines the indices across track, from west to east; index starts at 0 ;\n",
      "\tdatetime64[ns] time(time) ;\n",
      "\t\ttime:standard_name = time ;\n",
      "\t\ttime:axis = T ;\n",
      "\t\ttime:long_name = reference time for the measurements ;\n",
      "\t\ttime:comment = The time in this variable corresponds to the time in the time_reference global attribute ;\n",
      "\tfloat64 corner(corner) ;\n",
      "\t\tcorner:units = 1 ;\n",
      "\t\tcorner:long_name = pixel corner index ;\n",
      "\t\tcorner:comment = This coordinate variable defines the indices for the pixel corners; index starts a 0 (counter-clockwise, starting from south-western corner of the pixel in ascending part of the orbit). ;\n",
      "\tfloat32 latitude(time, scanline, ground_pixel) ;\n",
      "\t\tlatitude:long_name = pixel center latitude ;\n",
      "\t\tlatitude:units = degrees_north ;\n",
      "\t\tlatitude:standard_name = latitude ;\n",
      "\t\tlatitude:valid_min = -90.0 ;\n",
      "\t\tlatitude:valid_max = 90.0 ;\n",
      "\t\tlatitude:bounds = /PRODUCT/SUPPORT_DATA/GEOLOCATIONS/latitude_bounds ;\n",
      "\tfloat32 longitude(time, scanline, ground_pixel) ;\n",
      "\t\tlongitude:long_name = pixel center longitude ;\n",
      "\t\tlongitude:units = degrees_east ;\n",
      "\t\tlongitude:standard_name = longitude ;\n",
      "\t\tlongitude:valid_min = -180.0 ;\n",
      "\t\tlongitude:valid_max = 180.0 ;\n",
      "\t\tlongitude:bounds = /PRODUCT/SUPPORT_DATA/GEOLOCATIONS/longitude_bounds ;\n",
      "\tdatetime64[ns] delta_time(time, scanline, ground_pixel) ;\n",
      "\t\tdelta_time:long_name = offset from reference start time of measurement ;\n",
      "\tobject time_utc(time, scanline) ;\n",
      "\t\ttime_utc:long_name = Time of observation as ISO 8601 date-time string ;\n",
      "\tfloat32 qa_value(time, scanline, ground_pixel) ;\n",
      "\t\tqa_value:units = 1 ;\n",
      "\t\tqa_value:valid_min = 0 ;\n",
      "\t\tqa_value:valid_max = 100 ;\n",
      "\t\tqa_value:long_name = data quality value ;\n",
      "\t\tqa_value:comment = A continuous quality descriptor, varying between 0 (no data) and 1 (full quality data). Recommend to ignore data with qa_value < 0.5 ;\n",
      "\tfloat32 ozone_total_vertical_column(time, scanline, ground_pixel) ;\n",
      "\t\tozone_total_vertical_column:units = mol m-2 ;\n",
      "\t\tozone_total_vertical_column:standard_name = atmosphere_mole_content_of_ozone ;\n",
      "\t\tozone_total_vertical_column:long_name = total ozone column ;\n",
      "\t\tozone_total_vertical_column:multiplication_factor_to_convert_to_DU = 2241.14990234375 ;\n",
      "\t\tozone_total_vertical_column:multiplication_factor_to_convert_to_molecules_percm2 = 6.022139974343092e+19 ;\n",
      "\tfloat32 ozone_total_vertical_column_precision(time, scanline, ground_pixel) ;\n",
      "\t\tozone_total_vertical_column_precision:units = mol m-2 ;\n",
      "\t\tozone_total_vertical_column_precision:standard_name = atmosphere_mole_content_of_ozone error ;\n",
      "\t\tozone_total_vertical_column_precision:long_name = total ozone column random error ;\n",
      "\t\tozone_total_vertical_column_precision:multiplication_factor_to_convert_to_DU = 2241.14990234375 ;\n",
      "\t\tozone_total_vertical_column_precision:multiplication_factor_to_convert_to_molecules_percm2 = 6.022139974343092e+19 ;\n",
      "\tint32 layer(layer) ;\n",
      "\t\tlayer:units = 1 ;\n",
      "\t\tlayer:long_name = layer dimension index ;\n",
      "\tint32 level(level) ;\n",
      "\t\tlevel:units = 1 ;\n",
      "\t\tlevel:long_name = level dimension index ;\n",
      "\n",
      "// global attributes:\n",
      "}"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\\\Users\\\\joonw\\\\Downloads\\\\TCO_analysis\\\\20230209T.nc\\S5P_NRTI_L2__O3_____20230209T.nc\"\n",
    "\n",
    "ds = xr.open_dataset(file_path, group='PRODUCT')\n",
    "# Close the NetCDF file\n",
    "\n",
    "ds.head()\n",
    "# ds.close()\n",
    "ds.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time  scanline  ground_pixel  latitude\n",
      "1 2023-02-09       0.0           1.0  6.469116\n",
      "2 2023-02-09       0.0           2.0  6.501437\n",
      "3 2023-02-09       0.0           3.0  6.533309\n",
      "4 2023-02-09       0.0           4.0  6.564741\n",
      "          time  scanline  ground_pixel  latitude\n",
      "100 2023-02-09       0.0         100.0  9.228599\n",
      "101 2023-02-09       0.0         101.0  9.244569\n",
      "102 2023-02-09       0.0         102.0  9.260383\n",
      "103 2023-02-09       0.0         103.0  9.276043\n",
      "104 2023-02-09       0.0         104.0  9.291553\n",
      "          time  scanline  ground_pixel   latitude\n",
      "200 2023-02-09       0.0         200.0  10.336202\n",
      "201 2023-02-09       0.0         201.0  10.344195\n",
      "202 2023-02-09       0.0         202.0  10.352153\n",
      "203 2023-02-09       0.0         203.0  10.360074\n",
      "204 2023-02-09       0.0         204.0  10.367961\n",
      "            time  scanline  ground_pixel   latitude\n",
      "20000 2023-02-09      44.0         200.0  12.507050\n",
      "20001 2023-02-09      44.0         201.0  12.515080\n",
      "20002 2023-02-09      44.0         202.0  12.523075\n",
      "20003 2023-02-09      44.0         203.0  12.531033\n",
      "20004 2023-02-09      44.0         204.0  12.538955\n"
     ]
    }
   ],
   "source": [
    "dd = ds['time_utc']\n",
    "dd.to_dataframe().reset_index()\n",
    "\n",
    "\n",
    "dd = ds['latitude']\n",
    "dd = dd.to_dataframe().reset_index()\n",
    "\n",
    "print(dd.iloc[1:5,:])\n",
    "print(dd.iloc[100:105,:])\n",
    "print(dd.iloc[200:205,:])\n",
    "print(dd.iloc[20000:20005,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I want to use 'latitude', 'longitude', 'ozone_total_vertical_column' only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160650, 4)\n",
      "(160293, 4)\n"
     ]
    }
   ],
   "source": [
    "# Select specific variables\n",
    "selected_variables = ['latitude', 'longitude', 'delta_time', 'ozone_total_vertical_column']\n",
    "selected_ds = ds[selected_variables]\n",
    "\n",
    "# Convert xarray.Dataset to pandas DataFrame\n",
    "df = selected_ds.to_dataframe().reset_index()\n",
    "# Somehow this gives 6 columns\n",
    "\n",
    "df2 = df[['latitude', 'longitude', 'delta_time', 'ozone_total_vertical_column']]\n",
    "\n",
    "print(df2.shape)\n",
    "\n",
    "# Many NaNs\n",
    "\n",
    "df2_cleaned = df2.dropna(subset=['latitude', 'longitude', 'ozone_total_vertical_column'])\n",
    "\n",
    "# Print the resulting cleaned DataFrame\n",
    "print(df2_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to save the dataframe as csv file so chat I can work in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Assuming df2_cleaned is the cleaned DataFrame\n",
    "directory_path = r\"C:\\\\Users\\\\joonw\\Downloads\\\\TCO_analysis\"\n",
    "csv_file_path = os.path.join(directory_path, 'df2_cleaned.csv')\n",
    "# Save the DataFrame to a CSV file in the specified directory\n",
    "df2_cleaned.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to read HDF file in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pyhdf    # hd4\n",
    "from pyhdf.SD import SD\n",
    "import pandas as pd\n",
    "import xarray as xr # for netCDF4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sear surface temperature anomaly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types\n",
    "\n",
    "National Environmental Satellite, Data and Information Service(NESDIS)\n",
    "\n",
    "1) 2000 to 2020: Twice-weekly global 50km resolution HDF data.\n",
    "\n",
    "Each data correponds to one day (a single observation in a day) and has a shape of (238320, 4) with longitude, latitude and SST_anomaly and surface_flag. \n",
    "\n",
    "https://coralreefwatch.noaa.gov/product/50km/index.php\n",
    "\n",
    "2) 1985 to present: Daily regional 5km resolution NetCDF4 data.\n",
    "\n",
    "Each data correponds to one day(single observation in a day)  has a shape of (641602, 6),(341902) with  'time', 'longitude', 'latitude', 'sea_surface_temperature_anomaly', 'mask' and 'crs'.     \n",
    "\n",
    "https://coralreefwatch.noaa.gov/product/5km/index.php\n",
    "\n",
    "3) 2000 to 2020: 227 stations' time series data recorded twice-weekly. \n",
    "\n",
    "Each data contains observations from 2000 to 2020 with fixed longtidue and latitude.\n",
    "\n",
    "\n",
    "https://coralreefwatch.noaa.gov/product/50km/list_vs_group_latlon_201103.php\n",
    "\n",
    "\n",
    "#### Extract data from the website \n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW.html\n",
    "\n",
    "https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW.csv?CRW_SSTANOMALY%5B(2024-02-1T12:00:00Z):1:(2024-02-1T12:00:00Z)%5D%5B(-20):1:(20)%5D%5B(-20):1:(20)%5D\n",
    "\n",
    "\n",
    "Terminology:\n",
    "\n",
    "BAA: bleaching alert area    \n",
    "mask: pixel characteristics flag    \n",
    "DHW: degree heating week, Celsius weeks   \n",
    "HOTSPOT: coral bleaching hotspot, Celsius   \n",
    "SEAICE: sea ice fraction, 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if your HDF file is hdf4 or hdf5\n",
    "\n",
    "hdf4 format:  b'\\x0e\\x03\\x13\\x01'   \n",
    "hdf5 format:  b'\\x89HDF'   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf4_file_path = r\"C:\\\\Users\\\\joonw\\\\Downloads\\\\td1.hdf\"\n",
    "h=open(hdf4_file_path, 'rb'); bts=h.read(4); print(bts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_file = SD(hdf4_file_path)\n",
    "\n",
    "# Print a list of dataset names\n",
    "datasets = hdf_file.datasets()\n",
    "print(\"Available Datasets:\")\n",
    "for dataset_name in datasets:\n",
    "    print(dataset_name)\n",
    "    \n",
    "hdf_file.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_file = SD(hdf4_file_path)\n",
    "\n",
    "longitude_data = hdf_file.select(\"longitude\").get()\n",
    "latitude_data = hdf_file.select(\"latitude\").get()\n",
    "wind_data = hdf_file.select(\"CRW_SSTANOMALY\").get()\n",
    "\n",
    "hdf_file.end()\n",
    "\n",
    "# print(data1.shape)\n",
    "# print(data2.shape)\n",
    "# print(data3.shape)\n",
    "\n",
    "# Reshape latitude and longitude to match the wind data shape\n",
    "longitude_data2 = np.tile(longitude_data, (1, len(latitude_data )))\n",
    "latitude_data2 = np.repeat(latitude_data, len(longitude_data ))            # why longitude ordered - to + and latitude from + to -\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Longitude': longitude_data2.flatten(),\n",
    "    'Latitude': latitude_data2.flatten(),\n",
    "    'SST_Anomaly': wind_data.flatten()\n",
    "})\n",
    "\n",
    "print(df.shape)\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds534",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
